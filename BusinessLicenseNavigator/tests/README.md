# Business License Navigator - Test Suite

This directory contains the comprehensive test suite for the Business License Navigator system.

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ __init__.py              # Test package initialization
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ run_tests.py            # Main test runner
â”œâ”€â”€ test_config.py          # Test configuration and utilities
â”œâ”€â”€ test_integration.py     # Integration tests
â”œâ”€â”€ test_delaware_rag.py    # Delaware RAG tests
â”œâ”€â”€ test_delaware_mcp.py    # Delaware MCP tests
â””â”€â”€ test_generic_system.py  # Generic system tests
```

## ğŸ§ª Test Categories

### 1. **Unit Tests** (`--unit`)
Tests individual components in isolation:
- Agent module imports
- StateHandler functionality
- BusinessTypeHandler functionality
- MCPFactory functionality

### 2. **Delaware Tests** (`--delaware`)
Tests Delaware-specific functionality:
- Delaware RAG server
- Delaware MCP server
- Delaware-specific queries

### 3. **Generic System Tests** (`--generic`)
Tests the generic multi-state system:
- Generic state detection
- Generic industry detection
- Dynamic state creation
- Generic RAG server
- Generic MCP server
- Generic agent queries

### 4. **Integration Tests** (`--integration`)
Tests the complete system integration:
- End-to-end query processing
- Configuration validation
- Module imports
- Streamlit app functionality

## ğŸš€ Running Tests

### Run All Tests
```bash
python tests/run_tests.py
```

### Run Specific Test Categories
```bash
# Unit tests only
python tests/run_tests.py --unit

# Delaware tests only
python tests/run_tests.py --delaware

# Generic system tests only
python tests/run_tests.py --generic

# Integration tests only
python tests/run_tests.py --integration
```

### Run Individual Test Files
```bash
# Run specific test file
python tests/test_generic_system.py

# Run Delaware RAG tests
python tests/test_delaware_rag.py

# Run Delaware MCP tests
python tests/test_delaware_mcp.py

# Run integration tests
python tests/test_integration.py
```

## ğŸ“Š Test Output

The test runner provides detailed output including:

- **Test Progress**: Real-time progress indicators
- **Success/Failure Status**: Clear pass/fail indicators
- **Error Details**: Detailed error messages for failed tests
- **Performance Metrics**: Test duration and timing
- **Summary Report**: Overall test results summary

### Example Output
```
ğŸš€ Business License Navigator - Complete Test Suite
============================================================

ğŸ“‹ Running Unit Tests...
âœ… Agent module imported successfully
âœ… StateHandler imported and initialized successfully
âœ… BusinessTypeHandler imported and initialized successfully
âœ… MCPFactory imported and initialized successfully

ğŸ“‹ Running Delaware Tests...
âœ… Delaware RAG tests passed
âœ… Delaware MCP tests passed

ğŸ“‹ Running Generic System Tests...
âœ… Generic state detection test passed
âœ… Generic industry detection test passed
âœ… Generic agent queries test passed

ğŸ“‹ Running Integration Tests...
âœ… Integration tests passed

============================================================
ğŸ“Š Test Results Summary
============================================================
âœ… Passed: 12
âŒ Failed: 0
â±ï¸  Duration: 15.23 seconds

ğŸ‰ All tests passed! The system is ready to use.
```

## ğŸ”§ Test Configuration

The `test_config.py` file contains:

- **Test Settings**: Timeout values, retry attempts, log levels
- **Test Data**: Predefined test queries and expected results
- **Test Fixtures**: State configurations and business type data
- **Utility Functions**: Helper functions for test validation
- **Test Logger**: Consistent logging across all tests

## ğŸ“ Writing New Tests

### Adding Unit Tests
1. Create a new test function in the appropriate test file
2. Use the `TestLogger` for consistent output
3. Follow the naming convention: `test_<component_name>()`
4. Add the test to the test runner if needed

### Example Test Function
```python
def test_new_component():
    """Test new component functionality."""
    logger = TestLogger("New Component")
    
    try:
        # Test logic here
        result = some_function()
        
        if expected_condition:
            logger.success("Test passed")
            return True
        else:
            logger.error("Test failed")
            return False
            
    except Exception as e:
        logger.error(f"Test failed with exception: {e}")
        return False
```

### Adding Integration Tests
1. Add test cases to `test_integration.py`
2. Test end-to-end functionality
3. Validate system behavior with real queries
4. Test configuration and setup

## ğŸ› Debugging Tests

### Common Issues
1. **Import Errors**: Ensure parent directory is in Python path
2. **Timeout Errors**: Increase timeout in `test_config.py`
3. **Qdrant Connection**: Tests may fail if Qdrant server is not running
4. **API Key Issues**: Ensure environment variables are set

### Debug Mode
Run tests with verbose output:
```bash
python -v tests/run_tests.py
```

### Individual Test Debugging
```bash
# Run specific test with detailed output
python -c "
import sys
sys.path.append('.')
from tests.test_generic_system import test_generic_state_detection
test_generic_state_detection()
"
```

## ğŸ“ˆ Test Coverage

The test suite covers:

- âœ… **Core Components**: Agent, handlers, factories
- âœ… **State Management**: State detection, configuration
- âœ… **Business Logic**: Industry detection, license matching
- âœ… **RAG Systems**: Delaware and generic RAG servers
- âœ… **MCP Systems**: Delaware and generic MCP servers
- âœ… **Integration**: End-to-end query processing
- âœ… **Configuration**: JSON config validation
- âœ… **Error Handling**: Exception handling and fallbacks

## ğŸ”„ Continuous Integration

The test suite is designed to work with CI/CD systems:

- **Exit Codes**: Proper exit codes for CI systems
- **Timeout Protection**: Prevents hanging tests
- **Clean Output**: Structured output for CI parsing
- **Modular Design**: Can run specific test categories

## ğŸ“‹ Test Maintenance

### Regular Tasks
1. **Update Test Data**: Keep test queries current
2. **Add New States**: Update state configurations
3. **Add New Industries**: Update business type patterns
4. **Performance Monitoring**: Track test execution times
5. **Coverage Analysis**: Ensure new features are tested

### Best Practices
- Keep tests independent and isolated
- Use descriptive test names
- Include both positive and negative test cases
- Test edge cases and error conditions
- Maintain test data consistency
- Document test purpose and expected behavior 